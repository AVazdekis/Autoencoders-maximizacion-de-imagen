"""
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V5jHSryb7Gq-KJwarIRDIpXUCO8ToaXu
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5)),
    ])


mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)

data_loader = torch.utils.data.DataLoader(dataset=mnist_data,batch_size=64,shuffle=True)

mnist_data_valid = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

data_loader_valid = torch.utils.data.DataLoader(dataset=mnist_data_valid,batch_size=64, shuffle=True)



dataiter = iter(data_loader) #Convierte el DataLoader en un iterador lo que te permite recorrer el conjunto de datos por lotes.
images, labels = next(dataiter)
print(torch.min(images), torch.max(images))

class Autoencoder14x14(nn.Module):
    def __init__(self):
        super(Autoencoder14x14, self).__init__()
        self.encoder = nn.Sequential(
            # N, 1, 14, 14
            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        )

        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1,output_padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

model = Autoencoder14x14().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Entrenamiento
num_epochs = 4
outputs = []

for epoch in range(num_epochs):
  for images, _ in data_loader:
      images = images.to(device)
      imagen_redimensionada = F.interpolate(images, size=(14, 14), mode='bilinear', align_corners=False)
      #print(f'Imagen que se meten al autoendoder: {imagen_redimensionada.shape}')

      recon = model(imagen_redimensionada)
      print(f'Recon: {recon.shape}')

      loss = criterion(recon, images)

      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
  print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')

  #print(f'Recon: {recon.shape}')

#EvaluciÃ³n
model.eval()

dataiter = iter(data_loader_valid) #Convierte el data_loader_valid en un iterador lo que te permite recorrer el conjunto de datos por lotes.
images, labels = next(dataiter)


plt.figure(figsize=(9, 2))
plt.gray()


for i, img in enumerate(images[:9]):
    with torch.no_grad():
        imagen_redimensionada = F.interpolate(images, size=(14, 14), mode='bilinear', align_corners=False)
        imagen_redimensionada = imagen_redimensionada[i]
        pred = model(imagen_redimensionada)
        recon = pred[0].detach().numpy()
        recon2 = recon.reshape(-1, 28,28) # -> use for Autoencoder_Linear

        plt.subplot(2, 9, i+1)
        plt.imshow(img[0])

        plt.subplot(2, 9, i+1+9)
        plt.imshow(recon2[0])